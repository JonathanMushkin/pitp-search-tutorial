{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae25669-6259-4317-a597-55f37c0d5db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from scipy import signal, stats\n",
    "\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "\n",
    "TIME0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1c890-c82f-43ec-8e39-97d48461e30b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 \n",
    "Load the time domain data and Fourier transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dda5b-5e92-42be-b7b0-af689161150b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = Path(\"../strain.npy\")\n",
    "filename.exists()\n",
    "event_name = \"GW170817\"\n",
    "detector_name = \"H\"\n",
    "fs = 2**12  # Hz\n",
    "\n",
    "strain = np.load(filename)\n",
    "times = np.arange(len(strain)) / fs\n",
    "dt = times[1] - times[0]\n",
    "freqs = np.fft.rfftfreq(len(strain), d=dt)\n",
    "df = freqs[1] - freqs[0]\n",
    "\n",
    "tukey_window = signal.windows.tukey(M=len(strain), alpha=0.1)\n",
    "strain_f = np.fft.rfft(strain * tukey_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2612c41-2ead-4cd9-bdbc-7e29573d7155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# presenting the time domain signal after tueky widnow\n",
    "# NOT ASKED FOR IN THE EXAM\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(times, tukey_window * strain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bdd1d3-d368-4ee0-923b-db019cea16b9",
   "metadata": {},
   "source": [
    "## 2\n",
    "Estimate the ASD and create the whitening filter. **Create a log-log plot of the ASD from 20Hz onward**. **Create a log-log plot of the whitening filter from 20Hz onward. Plot the entire whitened strain data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3cf21-f535-40ec-8994-d2d360b41134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "welch_dict = {\n",
    "    \"x\": strain,\n",
    "    \"fs\": fs,\n",
    "    \"nperseg\": int(64 * fs),\n",
    "    \"noverlap\": int(32 * fs),\n",
    "    \"average\": \"median\",\n",
    "    \"scaling\": \"density\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5520571-3604-47f2-aae8-234a383f45cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "psd_freqs, psd_estimation = signal.welch(**welch_dict)\n",
    "fmin = 20\n",
    "asd = np.interp(freqs, psd_freqs, psd_estimation ** (1 / 2))\n",
    "i = np.searchsorted(psd_freqs, fmin)\n",
    "plt.loglog(psd_freqs[i:], psd_estimation[i:])\n",
    "plt.title(\"ASD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2267c46-b01a-4337-b9f8-11d0d89d5dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create high-pass filter\n",
    "highpass_filter = np.zeros(len(freqs))\n",
    "i1, i2 = np.searchsorted(freqs, (fmin, fmin + 1))\n",
    "highpass_filter[i1:i2] = np.sin(np.linspace(0, np.pi / 2, i2 - i1)) ** 2\n",
    "highpass_filter[i2:] = 1.0\n",
    "\n",
    "whitening_filter_raw = highpass_filter / np.interp(\n",
    "    x=freqs, xp=psd_freqs, fp=psd_estimation ** (1 / 2)\n",
    ")\n",
    "\n",
    "padded_tukey_window = np.pad(\n",
    "    signal.windows.tukey(M=int(64 * fs), alpha=0.1),\n",
    "    pad_width=(len(strain) - int(64 * fs)) // 2,\n",
    "    constant_values=0,\n",
    ")\n",
    "\n",
    "whitening_filter = (\n",
    "    highpass_filter\n",
    "    * np.fft.rfft(\n",
    "        np.fft.fftshift(\n",
    "            padded_tukey_window\n",
    "            * np.fft.fftshift(np.fft.irfft(whitening_filter_raw))\n",
    "        )\n",
    "    ).real\n",
    "    * np.sqrt(2 * dt)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e291de6-4f5a-4656-a0a7-b9bccd0116e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "_ = ax.loglog(freqs[i1:], np.abs(whitening_filter[i1:]))\n",
    "_ = ax.set_ylim(1e18)\n",
    "_ = ax.set_title(\"whitening filter\")\n",
    "_ = ax.set_xlabel(\"freq [Hz]\")\n",
    "_ = ax.set_ylabel(\"whitening filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b250a-051e-4cba-bfdd-b24dc6ad0a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(times, np.fft.irfft(strain_f * whitening_filter))\n",
    "plt.title(\"Whitened strain\")\n",
    "plt.xlabel(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ad5ad-da09-409b-af8e-f26780592e4a",
   "metadata": {},
   "source": [
    "## 3\n",
    "Create a single template for a search, with arbitrarily selected masses of $m_1=1.5$ and $m_2=1.25$ (in solar masses).  **Plot the time-domain template, such that it is localized in the middle of the time-axis. Fix the plot such that the waveform features are visible**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ea63b-e94e-4286-8c01-8083f0777aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gw_search_functions_SOLVED as gw_search_functions\n",
    "from importlib import reload\n",
    "\n",
    "reload(gw_search_functions)\n",
    "m1 = 1.5\n",
    "m2 = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f88942-d077-446f-8b2f-fd4e9337fd70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i1 = np.searchsorted(freqs, fmin)\n",
    "phase = np.zeros_like(freqs)\n",
    "phase[i1:] = gw_search_functions.masses_to_phases(m1, m2, freqs[i1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e8c4c-8601-4e21-82ff-5d5e705e8cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amp = np.zeros_like(freqs)\n",
    "amp[i1:] = freqs[i1:] ** (-7 / 6)\n",
    "h = amp * np.exp(1j * phase)\n",
    "normalization = np.fft.irfft(np.abs(h * whitening_filter) ** 2)[0] ** (1 / 2)\n",
    "h /= normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec457b-57ed-4308-bae8-852b6c2f8a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(times, np.fft.fftshift(np.fft.irfft(h)))\n",
    "plt.xlim(850, 1030)\n",
    "ax.set_xlabel(\"time [sec]\")\n",
    "ax.set_ylabel(\"h [arb.]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d42105-6d83-4762-8029-b9e6b2b82de5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4 \n",
    "Generate the complex-overlap time-series. **Plot a histogram with the real and imaginary parts of the complex-overlap, in a segment of data without an obvious glitch. Overlay the theoretical predictions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94997c51-8bab-4a8d-a767-b3f79500fb54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "whitened_strain_t = np.fft.irfft(strain_f * whitening_filter.conj())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24edcc-6baa-47c3-980a-2e01ed4d8c22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# zoom on glitch, to see where not to use the overlap timeseries\n",
    "plt.plot(times, whitened_strain_t)\n",
    "plt.xlim(1250, 1260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d9f72-559c-4ac3-8bee-27305bba82dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_cos = np.fft.irfft(\n",
    "    (strain_f * whitening_filter) * (h * whitening_filter).conj()\n",
    ")\n",
    "z_sin = np.fft.irfft(\n",
    "    (strain_f * whitening_filter) * (h * whitening_filter).conj() * 1j\n",
    ")\n",
    "z = z_cos + 1j * z_sin\n",
    "snr2 = np.abs(z) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884171de-a051-411c-9aaa-ba07bce32d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# indices without a glitch\n",
    "t_start = 200\n",
    "t_end = 1000\n",
    "tslice = slice(*np.searchsorted(times, (t_start, t_end)))\n",
    "# keywords for the histogram\n",
    "hist_kwargs = {\"bins\": 200, \"density\": True, \"log\": True, \"histtype\": \"step\"}\n",
    "# create 2 histograms\n",
    "counts, edges, patches = plt.hist(z_cos[tslice], **hist_kwargs, label=\"z_cos\")\n",
    "counts, edges, patches = plt.hist(z_sin[tslice], **hist_kwargs, label=\"z_sin\")\n",
    "# overlay normal distribution with mu=0 and sigma=1\n",
    "plt.plot(edges, stats.norm().pdf(edges), label=\"normal distribution\")\n",
    "plt.legend(loc=\"lower center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc9863-e758-4655-9fb4-9d4f48e753cf",
   "metadata": {},
   "source": [
    "# 5\n",
    "\n",
    "Create the ${\\rm SNR}^2$ time series.\n",
    "\n",
    "\n",
    "To verify your result, use the estimated ASD to draw mock data without a GW\n",
    "transient. Create the same ${\\rm SNR}^2$ time-series on this data. **On the same figure, plot\n",
    "the histograms of the ${\\rm SNR}^2$ of the real data and of the mock data. Overlay the\n",
    "theoretical prediction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ef6fe-9921-46b3-b834-d1fbf93dee53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the variance equally between the real and imaginary components of strain_f\n",
    "mock_strain_f = [1, 1j] @ stats.norm(scale=asd / np.sqrt(2)).rvs(\n",
    "    size=(2, len(freqs))\n",
    ")\n",
    "# multiply by a factor that relates to the duraion\n",
    "mock_strain_f *= len(times) / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c12a2-1357-4985-b391-e8c2d38d4f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.semilogy(freqs, np.abs(strain_f), alpha=0.5, label=\"strain\")\n",
    "plt.semilogy(freqs, np.abs(mock_strain_f), alpha=0.5, label=\"mock_strain\")\n",
    "plt.ylabel(r\"$|{\\rm strain}(f)|$\")\n",
    "plt.xlabel(\"frequency [Hz]\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160acb6c-bdfa-4c66-9c96-b35a55fe7938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the SNR^2 for the mock data\n",
    "mock_snr2 = (\n",
    "    np.abs(\n",
    "        np.fft.irfft(\n",
    "            (mock_strain_f * whitening_filter) * (h * whitening_filter).conj()\n",
    "        )\n",
    "        + 1j\n",
    "        * np.fft.irfft(\n",
    "            (mock_strain_f * whitening_filter)\n",
    "            * (h * whitening_filter).conj()\n",
    "            * 1j\n",
    "        )\n",
    "    )\n",
    "    ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138c56a-4980-4de9-a5a7-f63b02159242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_kwargs = {\n",
    "    \"histtype\": \"step\",\n",
    "    \"density\": True,\n",
    "    \"log\": True,\n",
    "    \"bins\": range(200),\n",
    "}\n",
    "\n",
    "counts, edges, patches = plt.hist(\n",
    "    snr2, **hist_kwargs, label=r\"real data SNR$^2$\"\n",
    ")\n",
    "counts, edges, pathes = plt.hist(\n",
    "    mock_snr2, **hist_kwargs, label=r\"mock data SNR$^2$\"\n",
    ")\n",
    "plt.plot(edges, stats.chi2(df=2).pdf(edges), label=r\"$\\chi^2(2)$ pdf\")\n",
    "# focus on interesting portion of the histogram\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(1 / np.diff(edges).mean() / len(snr2) / 10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83246fa-b29f-47df-834a-2efdf924f0f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6\n",
    "\n",
    "Create a test-statistic to detect glitches. Use it to remove glitches from the ${\\rm SNR}^2$ timeseries.\n",
    "**Plot the cleaned ${\\rm SNR}^{2}$ timeseries histogram. Overlay the theoretical prediction**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fff2a5-81c6-4836-9a9f-4bcc5531412e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find f_bar = where the cumulative SNR2 is equal half the overall SNR2\n",
    "frac_snr2 = np.cumsum(np.abs(h * whitening_filter) ** 2)\n",
    "frac_snr2 /= frac_snr2[-1]\n",
    "i_fbar = np.searchsorted(frac_snr2, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0a499-bf19-4a0d-8408-420e9cc37d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the the low and high frequencies templates\n",
    "h_low, h_high = np.zeros((2, len(freqs)), dtype=complex)\n",
    "# normalize them so each has norm 1\n",
    "h_low[:i_fbar] = h[:i_fbar] * np.sqrt(2)\n",
    "h_high[i_fbar:] = h[i_fbar:] * np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201a69f-afd8-4759-bd7e-b773baaccfa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check their normalization\n",
    "print(\n",
    "    \"<h|h> = \",\n",
    "    np.fft.irfft((h * whitening_filter) * (h * whitening_filter).conj())[0]\n",
    "    ** (1 / 2),\n",
    ")\n",
    "print(\n",
    "    \"<h_low | h_low> = \",\n",
    "    np.fft.irfft(\n",
    "        (h_low * whitening_filter) * (h_low * whitening_filter).conj()\n",
    "    )[0]\n",
    "    ** (1 / 2),\n",
    ")\n",
    "print(\n",
    "    \"<h_high | h_high> = \",\n",
    "    np.fft.irfft(\n",
    "        (h_high * whitening_filter) * (h_high * whitening_filter).conj()\n",
    "    )[0]\n",
    "    ** (1 / 2),\n",
    ")\n",
    "print(\n",
    "    \"<h_low| h_high> = \",\n",
    "    np.fft.irfft(\n",
    "        (h_high * whitening_filter) * (h_low * whitening_filter).conj()\n",
    "    )[0]\n",
    "    ** (1 / 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74401cf7-577c-45f8-ba4c-36380e003913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_low, z_high = [\n",
    "    (\n",
    "        np.fft.irfft(\n",
    "            strain_f * whitening_filter * (x * whitening_filter).conj()\n",
    "        )\n",
    "        + 1j\n",
    "        * np.fft.irfft(\n",
    "            strain_f * whitening_filter * (x * whitening_filter).conj() * 1j\n",
    "        )\n",
    "    )\n",
    "    for x in [h_low, h_high]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f6729-271c-4dc0-bcfa-cca4c3d430c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create 2 scatter plots of z_cos-z_sin (real vs imaginary) around and not around a glitch.\n",
    "# NOT ASKED FOR IN THE EXAM\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n",
    "tslice = slice(*np.searchsorted(times, (100, 101)))\n",
    "axs[0].scatter(\n",
    "    (z_low - z_high)[tslice].real,\n",
    "    (z_low - z_high)[tslice].imag,\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axs[0].set_title(\"not around glitch\")\n",
    "tslice = slice(*np.searchsorted(times, (1258, 1259)))\n",
    "axs[1].scatter(\n",
    "    (z_low - z_high)[tslice].real,\n",
    "    (z_low - z_high)[tslice].imag,\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axs[1].set_title(\"around glitch\")\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$z_\\cos - z_\\sin$ (real)\")\n",
    "    ax.set_ylabel(r\"$z_\\cos - z_\\sin$ (imaginary)\")\n",
    "    ax.text(0.05, 0.95, r\"NOT REQUIRED\", color=\"red\", transform=ax.transAxes)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c912994-07c3-456d-9925-1aa977d4e7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glitch_test_statistic = 0.5 * np.abs(z_low - z_high) ** 2\n",
    "glitch_test_threshold = stats.chi2(df=2).isf(\n",
    "    0.01\n",
    ")  # throw away one in a 100 good signals\n",
    "glitch_mask = (glitch_test_statistic > glitch_test_threshold) * (snr2 > 5**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49903bfe-a26d-4df3-8b3a-12f404c118ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "hist_kwargs = {\n",
    "    \"histtype\": \"step\",\n",
    "    \"density\": True,\n",
    "    \"log\": True,\n",
    "    \"bins\": range(200),\n",
    "}\n",
    "counts, edges, patches = ax.hist(\n",
    "    snr2, **hist_kwargs, label=r\"SNR$^2$ before glitch-vetoing\"\n",
    ")\n",
    "counts, edges, patches = ax.hist(\n",
    "    snr2[~glitch_mask], **hist_kwargs, label=r\"SNR$^2$ after glitch vetoing\"\n",
    ")\n",
    "\n",
    "\n",
    "ax.plot(edges, stats.chi2(df=2).pdf(edges), label=r\"$\\chi^2(2)$\")\n",
    "y_lower_limit = 0.5 / (np.diff(edges).mean() * len(snr2))\n",
    "ax.set_xlim(right=100)\n",
    "ax.set_ylim(y_lower_limit)\n",
    "leg = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ae9a3-ffb9-4cc6-81e4-ac06fb7dbe7d",
   "metadata": {},
   "source": [
    "# 7\n",
    "\n",
    " Now you know how to conduct a search with a single template. We now go on to prepare a bank of templates. The first step is to find a good linear basis to work with. Draw $\\sim2^8$ mass samples (see given functions). Create the waveform for each and perform SVD to find their phase basis-vectors. Choose the number of basis-vectors you want to use. **Plot the basis-vectors against frequency**. Make sure to read the guidance before performing the SVD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c402565-924f-4841-9a7b-43712785aa6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1, m2 = gw_search_functions.draw_mass_samples(2**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef66d7-c321-4fb8-8c4c-2daf626d0ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take sparser frequency grid\n",
    "fslice = slice(np.searchsorted(freqs, (fmin)), len(freqs), 128)\n",
    "fs = freqs[fslice]\n",
    "phases = np.array(\n",
    "    [\n",
    "        gw_search_functions.masses_to_phases(mm1, mm2, fs)\n",
    "        for mm1, mm2 in zip(m1, m2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680a223-69de-47bf-8037-46e4194b7067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wht_amp = (amp * whitening_filter)[fslice]\n",
    "wht_amp = wht_amp / np.sqrt(np.sum(wht_amp**2))  # renormalize\n",
    "\n",
    "linear_free_phases = gw_search_functions.phases_to_linear_free_phases(\n",
    "    phases, freqs[fslice], weights=wht_amp\n",
    ")\n",
    "common_phase_evolution = linear_free_phases.mean(axis=0)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs[fslice], linear_free_phases.T)\n",
    "_ = ax.plot(freqs[fslice], common_phase_evolution, ls=\"--\", c=\"k\")\n",
    "ax.text(0.75, 0.95, r\"NOT REQUIRED\", color=\"red\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57db0d-4227-4bc3-a110-1bd698c92d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phases_without_common_evolution = linear_free_phases - common_phase_evolution\n",
    "svd_phase = phases_without_common_evolution\n",
    "svd_weights = wht_amp\n",
    "print(svd_weights.shape, svd_phase.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e7232-19a7-41db-b5f4-fff7024645d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# could take up to 1-5 minutes.\n",
    "u, d, v = np.linalg.svd(svd_phase * svd_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255808f8-b020-4f24-ae16-81c757154b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(d[:20], \".\")\n",
    "ax.text(0.5, 0.95, r\"NOT REQUIRED\", color=\"red\", transform=ax.transAxes)\n",
    "ax.text(\n",
    "    0.5,\n",
    "    0.75,\n",
    "    r\"This is why we take 2 components\",\n",
    "    color=\"red\",\n",
    "    transform=ax.transAxes,\n",
    ")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4562e-1b25-45f7-98b5-c2514452f24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check that eignen vectors has zero weighted mean. Meaning, they are orthogonal to a constant function.\n",
    "(v[0] * svd_weights).mean(), (v[1] * svd_weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19528cbd-824b-46d6-8364-df8a1b38c9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = Path(\"local_outputs\")\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir()\n",
    "np.savez(\n",
    "    output_dir / \"GW170817_H_svd\", u=u, d=d, v=v, freqs_sliced=fs, freqs=freqs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9034a-742b-4389-b8d1-737747ceff1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u, d, v = [\n",
    "    np.load(output_dir / \"GW170817_H_svd.npz\").get(k) for k in (\"u\", \"d\", \"v\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd260955-d096-4251-bc4a-c8bc0e9282ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick 2 coordinates\n",
    "ndim = 2\n",
    "u = u[:, :ndim]\n",
    "d = d[:ndim]\n",
    "v = v[:ndim, :]\n",
    "\n",
    "# create a phase vector (without weights) from SVD components\n",
    "# and new set of coordiantes\n",
    "coordinates = u * d\n",
    "\n",
    "phase_basis_coarse_freqs = np.zeros_like(v)\n",
    "mask = svd_weights != 0\n",
    "phase_basis_coarse_freqs[:, mask] = v[:, mask] / svd_weights[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662cf57-15d6-4214-b0e3-28121984b717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalization tests\n",
    "print(\"NOT REQUIRED\")\n",
    "print(\"SVD weights norm:\", np.sum(svd_weights**2))\n",
    "print(\n",
    "    \"First basis norm:\",\n",
    "    np.sum(svd_weights**2 * phase_basis_coarse_freqs[0] ** 2),\n",
    ")\n",
    "print(\n",
    "    \"Const. component in first basis:\",\n",
    "    np.sum(svd_weights**2 * phase_basis_coarse_freqs[1]),\n",
    ")\n",
    "print(\n",
    "    \"Second basis norm:\",\n",
    "    np.sum(svd_weights**2 * phase_basis_coarse_freqs[0] ** 2),\n",
    ")\n",
    "print(\n",
    "    \"Const. component in second basis:\",\n",
    "    np.sum(svd_weights**2 * phase_basis_coarse_freqs[0]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99d8d9-7490-46ab-a17c-ccf946f6a4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(phase_basis_coarse_freqs[0], label=\"1st component\")\n",
    "ax.plot(phase_basis_coarse_freqs[1], label=\"2nd component\")\n",
    "ax.grid()\n",
    "leg = ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626418b2-ec50-4869-bac2-476353bb9ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create full-frequency resolution phase basis\n",
    "phase_basis = np.array(\n",
    "    [\n",
    "        np.interp(x=freqs, xp=freqs[fslice], fp=phase_base, left=0)\n",
    "        for phase_base in phase_basis_coarse_freqs\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04da611-b528-4677-b59b-9e0da9b19f62",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  8\n",
    "\n",
    "Calculate the inner product between waveforms at different coordinate-distance $\\sqrt{\\sum_\\alpha |\\Delta c_\\alpha |^2)}$.\n",
    "**Plot their overlap against their distance, and the theoretical prediction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c3251-1e06-4a25-a4cd-e3c409586ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distances = 10 ** np.linspace(-2, 0.5, num=30)\n",
    "amp = np.zeros_like(freqs[fslice])\n",
    "cond = whitening_filter[fslice] != 0\n",
    "amp[cond] = freqs[fslice][cond] ** (-7 / 6)\n",
    "amp_wht = amp * whitening_filter[fslice]\n",
    "amp_wht /= np.sqrt(np.sum((amp_wht) ** 2))\n",
    "\n",
    "matches = np.zeros_like(distances)\n",
    "for i, distance in enumerate(distances):\n",
    "    dist_per_coordinate = distance / np.sqrt(2)\n",
    "    coordinate = np.array([dist_per_coordinate, dist_per_coordinate])\n",
    "    phase = coordinate @ phase_basis_coarse_freqs + common_phase_evolution\n",
    "    matches[i] = np.sum(\n",
    "        amp_wht\n",
    "        * np.exp(-1j * phase)\n",
    "        * amp_wht\n",
    "        * np.exp(+1j * common_phase_evolution)\n",
    "    ).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c02c7c-a09b-4ba6-82ed-39e1b9f28870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.loglog(distances**2, 1 - matches, label=\"$1 - $ match\")\n",
    "ax.loglog(\n",
    "    distances**2,\n",
    "    distances**2 / 2,\n",
    "    \".\",\n",
    "    label=r\"$1-\\frac{1}{2}\\sum_\\alpha|\\Delta c_\\alpha |^2$\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(r\"distance = $\\sum_\\alpha |\\Delta c_\\alpha |^2$\")\n",
    "ax.set_ylabel(\"mismatch = $1 - $match\")\n",
    "leg = ax.legend(loc=\"upper left\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef26412-71dc-4fbc-a9a9-26b0a3e1a7e4",
   "metadata": {},
   "source": [
    "# 9 \n",
    "\n",
    "Draw $2^{13}$ mass samples. Create the phase for each, and find the coordinates of each.\n",
    "Select a subset such that the distance between any 2 samples is not smaller than 0.1. \n",
    "\n",
    "On the same plot, create a scatter plot of the 213 samples and of the selected subset.\n",
    "On the plot, write down the size of subset. This subset defines the search bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53695b1-712b-4ed9-8057-fc51b49080ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fslice = slice(np.searchsorted(freqs, (fmin)), len(freqs), 128)\n",
    "freqs_low_res = freqs[fslice]\n",
    "\n",
    "m1, m2 = gw_search_functions.draw_mass_samples(2**13)\n",
    "redshift = 0.01\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(m1, m2, marker=\".\", s=1)\n",
    "ax.scatter(1.46 * (1 + redshift), 1.27 * (1 + redshift), s=100, marker=\"x\")\n",
    "ax.text(0.5, 0.95, r\"NOT REQUIRED\", color=\"red\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6245290e-8e0a-49bb-be4a-4418250993e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phases_on_coarse_freqs = np.array(\n",
    "    [\n",
    "        gw_search_functions.masses_to_phases(mm1, mm2, freqs_low_res)\n",
    "        for mm1, mm2 in zip(m1, m2)\n",
    "    ]\n",
    ")\n",
    "linear_free_phases = gw_search_functions.phases_to_linear_free_phases(\n",
    "    phases_on_coarse_freqs, freqs_low_res, amp_wht\n",
    ")\n",
    "\n",
    "phases_without_common_evolution = linear_free_phases - common_phase_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32218b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, nrows=1)\n",
    "\n",
    "axs[0].plot(freqs_low_res, linear_free_phases[:64].T)\n",
    "axs[0].plot(freqs_low_res, common_phase_evolution, ls=\"--\", c=\"k\")\n",
    "axs[1].plot(freqs_low_res, phases_without_common_evolution[:64].T)\n",
    "for ax in axs:\n",
    "    ax.text(0.5, 0.95, r\"NOT REQUIRED\", color=\"red\", transform=ax.transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af05bac-d04c-4e8c-a0f0-6b24aa407c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coordinates = (\n",
    "    svd_weights**2 * phases_without_common_evolution\n",
    ") @ phase_basis_coarse_freqs.T\n",
    "\n",
    "bank_coordinates, bank_indices = (\n",
    "    gw_search_functions.select_points_without_clutter(\n",
    "        coordinates, np.sqrt(0.1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793354f-0765-48a1-b888-2f0bf56e6348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    *coordinates.T,\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    "    c=\"r\",\n",
    "    label=f\"full set ({len(coordinates)} points)\",\n",
    ")\n",
    "plt.scatter(\n",
    "    *bank_coordinates.T,\n",
    "    s=5,\n",
    "    c=\"k\",\n",
    "    label=f\"subset ({len(bank_coordinates)} points)\",\n",
    ")\n",
    "print(bank_coordinates.shape)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f9b24-a5d6-4b1b-8189-f8cf77a03aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amp = np.zeros_like(freqs)\n",
    "amp[i1:] = freqs[i1:] ** (-7 / 6)\n",
    "normalization = gw_search_functions.correlate(amp, amp, w=whitening_filter)[\n",
    "    0\n",
    "] ** (1 / 2)\n",
    "amp /= normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5e5a9",
   "metadata": {},
   "source": [
    "# 10\n",
    "\n",
    "Repeat the search (sections 4-6, without repeating their plots) for each template in the bank individually (including glitch-removal). For each interval of 0.1 seconds, record which template gave the maximal SNR, and what was that SNR. **Plot the time-series of maximal SNR$^2$ in per 0.1 seconds. Plot a histogram of the maximal values per 0.1 seconds**. *Before using the entire bank, try a small subset and see that the results make sense. The entire search could take several minutes, depending on hardware*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48c0db-c1bc-4f35-ae32-234aa2078cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices_lists = []\n",
    "snr2_lists = []\n",
    "min_snr2_to_save = stats.chi2(df=2).isf(1 / (times[-1] / 0.1))\n",
    "glitch_test_threshold = stats.chi2(df=2).isf(0.01)\n",
    "snr2_lists_raw = []\n",
    "indices_lists_raw = []\n",
    "glitch_mask_list = []\n",
    "common_phase_evolution_high_res = np.interp(\n",
    "    x=freqs, xp=freqs_low_res, fp=common_phase_evolution\n",
    ")\n",
    "fs = 1 / dt\n",
    "t_start = time.time()\n",
    "\n",
    "for template_index, template_coordinate in tqdm(\n",
    "    enumerate(bank_coordinates), total=len(bank_coordinates), desc=\"template\"\n",
    "):\n",
    "    phase = common_phase_evolution_high_res + template_coordinate @ phase_basis\n",
    "    h = amp * np.exp(1j * phase)\n",
    "\n",
    "    snr2 = gw_search_functions.snr2_timeseries(\n",
    "        h * whitening_filter, strain_f * whitening_filter\n",
    "    )\n",
    "    h_low, h_high = np.zeros((2, len(freqs)), complex)\n",
    "    h_low[:i_fbar] = h[:i_fbar]\n",
    "    h_high[i_fbar:] = h[i_fbar:]\n",
    "    z_low = gw_search_functions.complex_overlap_timeseries(\n",
    "        h_low * whitening_filter, strain_f * whitening_filter\n",
    "    )\n",
    "    z_high = gw_search_functions.complex_overlap_timeseries(\n",
    "        h_high * whitening_filter, strain_f * whitening_filter\n",
    "    )\n",
    "\n",
    "    glitch_test_statistic = np.abs(z_low - z_high) ** 2\n",
    "\n",
    "    glitch_mask = (glitch_test_statistic > glitch_test_threshold) * (snr2 > 10)\n",
    "    glitch_mask_list.append(glitch_mask)\n",
    "    maxs, argmaxs = gw_search_functions.max_argmax_over_n_samples(\n",
    "        snr2 * ~glitch_mask, int(0.1 * fs)\n",
    "    )\n",
    "    indices_lists.append(argmaxs)\n",
    "    snr2_lists.append(maxs)\n",
    "\n",
    "    maxs, argmaxs = gw_search_functions.max_argmax_over_n_samples(\n",
    "        snr2, int(0.1 * fs)\n",
    "    )\n",
    "    indices_lists_raw.append(argmaxs)\n",
    "    snr2_lists_raw.append(maxs)\n",
    "\n",
    "snr2_per_template = np.array(snr2_lists)\n",
    "time_indices_per_template = np.array(indices_lists)\n",
    "snr2_per_template_with_glitches = np.array(snr2_lists_raw)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bins = np.linspace(0, times[-1], snr2_per_template.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a54992",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(time_bins, snr2_per_template.max(axis=0))\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_ylabel(r\"Bestfit ${\\rm SNR}^2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73399196-7695-4680-91be-ad5c03b42739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "hist_kwargs = {\"histtype\": \"step\", \"density\": True, \"log\": True, \"bins\": 200}\n",
    "counts, edges, patches = ax.hist(\n",
    "    snr2_per_template.max(axis=0),\n",
    "    **hist_kwargs,\n",
    "    alpha=0.5,\n",
    "    label=\"With glitch removal\",\n",
    ")\n",
    "\n",
    "hist_kwargs = {\"histtype\": \"step\", \"density\": True, \"log\": True, \"bins\": 200}\n",
    "counts, edges, patches = ax.hist(\n",
    "    snr2_per_template_with_glitches.max(axis=0).flatten(),\n",
    "    label=\"Before glitch removal\",\n",
    "    **hist_kwargs,\n",
    "    ls=\"--\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(r\"${\\rm SNR}^2$\")\n",
    "ax.set_ylabel(\"counts (normalized)\")\n",
    "leg = ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d8538-f325-4035-861a-c067509ae5c9",
   "metadata": {},
   "source": [
    "## 11.\n",
    "If you detected an event, **report its time, the masses of the template and an estimation or a upper bound of the false-alarm rate for such SNR**. Consider the number of templates you used and the fact that waveforms have typical auto-correlation length of 1 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a01b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with https://arxiv.org/pdf/1710.05832 Table 1\n",
    "best_template_index, best_timestamp_index = np.unravel_index(\n",
    "    snr2_per_template.argmax(), snr2_per_template.shape\n",
    ")\n",
    "bestfit_m1 = m1[best_template_index]\n",
    "bestfit_m2 = m2[best_template_index]\n",
    "bestfit_mchirp = gw_search_functions.m1m2_to_mchirp(bestfit_m1, bestfit_m2)\n",
    "bestfit_snr2 = snr2_per_template.max()\n",
    "time_bins = np.linspace(0, times[-1], snr2_per_template.shape[1])\n",
    "bestfit_time = snr2_per_template.max(axis=0).argmax()\n",
    "\n",
    "print(\"NOT REQUIRED\")\n",
    "print(f\"Maximal SNR^2 found : {bestfit_snr2:.5g} at time {bestfit_time:.3g}\")\n",
    "print(\n",
    "    f\"Template of masses ({bestfit_m1:.3g},{bestfit_m2:.3g}), or chirp-mass {bestfit_mchirp:.5g} (solar masses)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2a6af",
   "metadata": {},
   "source": [
    "\n",
    "p = Probability that non of N = N_templates * N_times individual experiments will reach value x or higher :\n",
    "$$p = 1 - (SF(x))^N$$\n",
    "\n",
    "Probability that at least one of $N$ experiments will reach value x:\n",
    "$1 - p = (SF(x))^N $\n",
    "\n",
    "At this high SNR^2, the FAR is almost exactly zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbf7f7-dd5c-4d5c-8ca0-7b02b33e315e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_templates = bank_coordinates.shape[0]\n",
    "N_trials = N_templates * len(times)\n",
    "\n",
    "stats.chi2(df=2).sf(snr2_per_template.max()) ** N_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f86a4-1827-4668-b61b-d96e2ae64d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.log(1 - stats.chi2(df).sf(snr2_per_template.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bb143-e0de-4396-a317-8159fa17614e",
   "metadata": {
    "tags": []
   },
   "source": [
    "use binomial to imporve the calculation\n",
    "\n",
    "$$ FAR = 1 - CDF(x)^N = 1 - (1-SF(x))^N \\approx 1 - 1 + N\\cdot SF(x) = N\\cdot SF(x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9120e7-bd20-4326-86b9-2d03583df054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snr2_per_template.size * stats.chi2(df=2).sf(snr2_per_template.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c634856b",
   "metadata": {},
   "source": [
    "## 12.\n",
    "\n",
    "**Create a spectogram (using e.g. `matplotlib.pyplot.specgram`), localized in time and frequency around the event you found**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a0c47-48dc-4891-861b-641c2765ce8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the histogram in 2 steps. So I can calibrate the dynamic range in the second histogram using the fist histogram\n",
    "specgram_kwargs = {\n",
    "    \"x\": np.fft.irfft(strain_f * whitening_filter),\n",
    "    \"NFFT\": int(fs * 0.5),\n",
    "    \"noverlap\": int(fs * 0.25),\n",
    "    \"scale\": \"linear\",\n",
    "    \"vmin\": 0,\n",
    "    \"vmax\": 25,\n",
    "    \"Fs\": fs,\n",
    "}\n",
    "\n",
    "o = plt.specgram(**specgram_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220fe32e-301c-4d9f-8180-1d4d6fb861ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "specgram_kwargs = {\n",
    "    \"x\": np.fft.irfft(strain_f * whitening_filter),\n",
    "    \"NFFT\": int(fs * 0.5),\n",
    "    \"noverlap\": int(fs * 0.25),\n",
    "    \"scale\": \"linear\",\n",
    "    \"vmin\": 0,\n",
    "    \"vmax\": o[0][(o[1] > 20) * (o[1] < 1000)].std() * 5,\n",
    "    \"Fs\": fs,\n",
    "}\n",
    "\n",
    "o = plt.specgram(**specgram_kwargs)\n",
    "tmin = 0.1 * 10259 - 6\n",
    "tmax = 0.1 * 10259 + 1\n",
    "fmin = 20\n",
    "fmax = 1000\n",
    "plt.xlim(tmin, tmax)\n",
    "plt.ylim(20, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12794d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME1 = time.time()\n",
    "\n",
    "print(f\"Time passed: {TIME1 - TIME0:.3g} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw_detection_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
