{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This assignment is the first part of two exercises, in which we will analyze LIGO data to find the gravitational wave transient caused by the coalescence of two neutron stars (GW170817).\n",
    "\n",
    "You are given a true 2048-second segment of Hanford LIGO data, sampled at 4096 Hz (down-sampled from the original 16 kHz data). Along with this PDF, you should have:\n",
    "\n",
    "1. `strain.npy`, readable by NumPy, containing the strain data.\n",
    "2. `gw_search_functions`, containing helpful functions, constants.\n",
    "3. The timestamps corresponding to the strain are not uploaded due to size, and are instead provided in `gw_search_functions`.\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will practice using FFT/RFFT to perform a matched-filter search in the data and compute a test statistic. Special attention will be given to understanding the **normalization** of inputs and the expected test statistic values. Finally, we will apply a glitch-removal procedure to the data.\n",
    "\n",
    "It is advised to get this code from https://github.com/JonathanMushkin/GW_search_tutorial, and use the pyproject.toml to define an environment.\n",
    "\n",
    "Please contact jonathan.mushkin[at]weizmann.ac.il for any help, question or comment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Under the null and signal hypotheses, the data model is:\n",
    "\n",
    "$$\n",
    "H_0: \\quad s(t) = n(t) \\\\\n",
    "H_1: \\quad s(t) = n(t) + h(t)\n",
    "$$\n",
    "\n",
    "The noise $n(t)$ is approximately stationary and Gaussian with a certain power spectral density $S_n(f)$. This is only approximately true for two reasons:  \n",
    "1. The spectral shape changes smoothly over a few seconds.  \n",
    "2. There are *glitches* â€” unexplained, time-localized loud transients.\n",
    "\n",
    "Under the Gaussian noise approximation, the log-likelihood of waveform $h$ given strain data $s$ is:\n",
    "\n",
    "$$\n",
    "\\ln \\mathcal{L} = \\Re \\langle h, s \\rangle - \\frac{1}{2} \\langle h, h \\rangle\n",
    "$$\n",
    "\n",
    "with the inner product defined as:\n",
    "\n",
    "$$\n",
    "\\langle a, b \\rangle = \\sum_f \\frac{a(f) b^\\ast(f)}{S_n(f)}\\,\\mathrm{d}f = \\sum_f \\tilde{a}(f) \\tilde{b}^\\ast(f)\\,\\mathrm{d}f\n",
    "$$\n",
    "\n",
    "where the tilde denotes the whitened series.\n",
    "\n",
    "The strain signal at the detector is a linear combination of the two polarizations:\n",
    "\n",
    "$$\n",
    "h(f) = F_+ h_+(f) + F_\\times h_\\times(f)\n",
    "$$\n",
    "\n",
    "Under the non-precessing, dominant-mode approximation, the polarization components satisfy:\n",
    "\n",
    "$$\n",
    "h_\\times(f) = i\\, h_+(f)\n",
    "$$\n",
    "\n",
    "(i.e., a sine in one is a cosine in the other). The detector response can thus be treated as a complex amplitude and maximized over. \n",
    "\n",
    "We define the complex overlap time series using \"inverted convolution\" notation:\n",
    "\n",
    "$$\n",
    "z(t) = z_{\\cos}(t) + i\\, z_{\\sin}(t) = (\\tilde{s} \\ast \\overleftarrow{\\tilde{h}_+})(t) + i\\, (\\tilde{s} \\ast \\overleftarrow{\\tilde{h}_\\times})(t)\n",
    "$$\n",
    "\n",
    "Using a normalization such that:\n",
    "\n",
    "$$\n",
    "\\langle h_+, h_+ \\rangle = 1,\n",
    "$$\n",
    "\n",
    "the Signal-to-Noise Ratio (SNR) time series is:\n",
    "\n",
    "$$\n",
    "\\text{SNR}^2(t) = |z(t)|^2 = |z_{\\cos}(t)|^2 + |z_{\\sin}(t)|^2\n",
    "$$\n",
    "\n",
    "and the log-likelihood becomes:\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L} = \\frac{1}{2} \\text{SNR}^2(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "import gw_search_functions\n",
    "\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 12\n",
    "plt.rcParams[\"axes.titlesize\"] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 \n",
    "Load the time domain data and Fourier transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"strain.npy\"\n",
    "event_name = \"GW170817\"\n",
    "detector_name = \"H\"\n",
    "fs = 2**12  # Hz\n",
    "\n",
    "strain = np.load(filename)\n",
    "times = np.arange(len(strain)) / fs\n",
    "dt = times[1] - times[0]\n",
    "freqs = np.fft.rfftfreq(len(strain), d=dt)\n",
    "df = freqs[1] - freqs[0]\n",
    "\n",
    "tukey_window = signal.windows.tukey(M=len(strain), alpha=0.1)\n",
    "strain_f = np.fft.rfft(strain * tukey_window)\n",
    "\n",
    "# presenting the time domain signal after tueky widnow\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(times, tukey_window * strain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2\n",
    "In the next few cells we walk through the whitening of the data. We use the Welch method, and remove by force frequencies below 20 Hz. The latter is due to FFT artifacts due to the GW signal lengths, the duration of the data, and the assumed preiodicity in FFT framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seg_duration = 64\n",
    "overlap_duration = 32\n",
    "nperseg = int(seg_duration * fs)\n",
    "noverlap = int(overlap_duration * fs)\n",
    "welch_dict = {\n",
    "    \"x\": strain,\n",
    "    \"fs\": fs,\n",
    "    \"nperseg\": nperseg,\n",
    "    \"noverlap\": noverlap,\n",
    "    \"average\": \"median\",\n",
    "    \"scaling\": \"density\",\n",
    "}\n",
    "psd_freqs, psd_estimation = signal.welch(**welch_dict)\n",
    "asd_estimation = psd_estimation**(1/2)\n",
    "fmin = 20\n",
    "asd = np.interp(freqs, psd_freqs, asd_estimation)\n",
    "min_idx = np.searchsorted(psd_freqs, fmin)\n",
    "plt.loglog(psd_freqs[min_idx:], asd_estimation[min_idx:])\n",
    "plt.title(\"ASD\")\n",
    "plt.xlabel(\"Freq. [Hz]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create high-pass filter\n",
    "# make it go like sin-squared from 0 to 1 over (fmin, fmin+1Hz) interval\n",
    "highpass_filter = np.zeros(len(freqs))\n",
    "i1, i2 = np.searchsorted(freqs, (fmin, fmin + 1))\n",
    "highpass_filter[i1:i2] = np.sin(np.linspace(0, np.pi / 2, i2 - i1)) ** 2\n",
    "highpass_filter[i2:] = 1.0\n",
    "\n",
    "# whitening filter is 1/asd(f) * high-pass filter\n",
    "whitening_filter_raw = highpass_filter / np.interp(\n",
    "    x=freqs, xp=psd_freqs, fp=asd_estimation\n",
    ")\n",
    "\n",
    "# To avoid ripples in Fourier domain, we apply a windowing in time domain\n",
    "\n",
    "padded_tukey_window = np.fft.fftshift(\n",
    "    np.pad(\n",
    "        signal.windows.tukey(M=nperseg, alpha=0.1),\n",
    "        pad_width=(len(strain) - nperseg) // 2,\n",
    "        constant_values=0,\n",
    "    )\n",
    ")\n",
    "# tranform to time domain, apply the window, and return to frequency domain\n",
    "whitening_filter = (\n",
    "    highpass_filter\n",
    "    * np.fft.rfft(padded_tukey_window * np.fft.irfft(whitening_filter_raw))\n",
    ").real * np.sqrt(2 * dt)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "_ = ax.loglog(freqs[i1:], whitening_filter[i1:])\n",
    "_ = ax.set_ylim(1e18)\n",
    "_ = ax.set_title(\"whitening filter\")\n",
    "_ = ax.set_xlabel(\"freq [Hz]\")\n",
    "_ = ax.set_ylabel(\"whitening filter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "**Use the (frequency domain) whitening filter on the data. Find a very obvious \"glitch\" in the time-domain whitened data. Plot a histogram of the real and imaginary parts of the whitened time-domain strain, with samples from a glitchless region.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wht_strain_f = strain_f  # this is wrong\n",
    "wht_strain_t = strain # this is wrong\n",
    "plt.plot(times, wht_strain_t)\n",
    "plt.title(\"Whitened strain\")\n",
    "plt.xlabel(\"time\")\n",
    "\n",
    "plt.figure()\n",
    "counts, bins, _ = plt.hist(\n",
    "    wht_strain_t[:], # this is wrong\n",
    "    log=True,\n",
    "    bins=100,\n",
    "    density=True,\n",
    ")\n",
    "\n",
    "plt.plot(bins, 1/bins**2) # this is wrong "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3\n",
    "Create a single template for a search, with arbitrarily selected masses of $m_1=1.5$ and $m_2=1.25$ (in solar masses). \n",
    "\n",
    "Remove frequencies below 20 Hz due to FFT artifacts due to the signal length and waveform length. \n",
    "\n",
    "Perform a linear-free transformation on the phase, to remove an arbitrary phase and time shift in a standardize way. The code to do it is attached. See https://arxiv.org/abs/1904.01683 for the derivation.\n",
    "\n",
    "**Plot the time-domain templates, with and without the linear-free time shift, such that they iare localized in the middle of the time-axis. Set the plot limits such that the waveform features and differences are visible.**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1 = 1.5\n",
    "m2 = 1.25\n",
    "fmin = 20\n",
    "i1 = np.searchsorted(freqs, fmin)\n",
    "phase = np.zeros_like(freqs)\n",
    "phase[i1:] = gw_search_functions.masses_to_phases(m1, m2, freqs[i1:])\n",
    "amp = np.zeros_like(freqs)\n",
    "amp[i1:] = freqs[i1:] ** (-7 / 6)\n",
    "h = amp * np.exp(1j * phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = amp * whitening_filter\n",
    "weights /= np.sum(weights**2) ** (1 / 2)\n",
    "phase_linear_free = gw_search_functions.phases_to_linear_free_phases(phase, freqs, weights)\n",
    "h_linear_free = amp * np.exp(1j * phase_linear_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(times, np.fft.fftshift(np.fft.irfft(h)))\n",
    "ax.plot(times, np.fft.fftshift(np.fft.irfft(h_linear_free)))\n",
    "plt.xlim(850, 1030)\n",
    "ax.set_xlabel(\"time [sec]\")\n",
    "ax.set_ylabel(\"h [arb.]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4 \n",
    "\n",
    "Prepare the template for use. \n",
    "\n",
    "**Make sure it is normalized such that it it appears with amplitude 1 in the data, the auto-correlation function will return 1 in the zero-lag.** \n",
    "\n",
    "Then, Generate the complex-overlap time-series. \n",
    "\n",
    "**Plot a histogram with the real and imaginary parts of the complex-overlap, in a segment of data without an obvious glitch. Overlay the theoretical predictions**.\n",
    "\n",
    "The theoretical prediction for the complex-overlaps is that they'll follow a normal distribution. See that you understand why (single line of calculations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = 1  # this is wrong\n",
    "h_linear_free = h_linear_free * normalization\n",
    "wht_template = h_linear_free * whitening_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complex overlaps\n",
    "z_cos = np.fft.irfft(wht_strain_f * wht_template.conj())\n",
    "z_sin = np.fft.irfft(wht_strain_f * (1j * wht_template).conj())\n",
    "z = z_cos + 1j * z_sin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# indices without a glitch\n",
    "t_start = 0  # this is wrong\n",
    "t_end = len(times)  # this is wrong\n",
    "tslice = slice(*np.searchsorted(times, (t_start, t_end)))\n",
    "# keywords for the histogram\n",
    "hist_kwargs = {\"bins\": 200, \"density\": True, \"log\": True, \"histtype\": \"step\"}\n",
    "# create 2 histograms\n",
    "counts, edges, patches = plt.hist(z_cos[tslice], **hist_kwargs, label=\"z_cos\")\n",
    "counts, edges, patches = plt.hist(z_sin[tslice], **hist_kwargs, label=\"z_sin\")\n",
    "# overlay normal distribution with mu=0 and sigma=1\n",
    "plt.plot(edges, stats.norm().pdf(edges), label=\"normal distribution\")\n",
    "plt.legend(loc=\"lower center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# 5\n",
    "**compute the $\\text{SNR}^2$ times series**.\n",
    "\n",
    "To verify your result SNR-timeseries results, use the estimated ASD to draw mock data without a GW\n",
    "transient. Due to FFT-ology, the code below already does that. \n",
    "\n",
    "**Create the ${\\rm SNR}^2$ time-series on the mock data.**\n",
    "\n",
    "**On the same figure, plot\n",
    "the histograms of the ${\\rm SNR}^2$ of the real data and of the mock data. Overlay the\n",
    "theoretical prediction**.\n",
    "\n",
    "Do you understand why the test statistic follows the $\\chi^2(2)$ distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr2 = np.abs(z) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = len(strain)\n",
    "freqs = np.fft.rfftfreq(N, d=1 / fs)\n",
    "sigma = asd * np.sqrt(fs * N) / 2\n",
    "\n",
    "re = np.random.normal(scale=sigma, size=len(freqs))\n",
    "im = np.random.normal(scale=sigma, size=len(freqs))\n",
    "mock_strain_f = re + 1j * im\n",
    "\n",
    "# DC and Nyquist (real only)\n",
    "mock_strain_f[0] = np.random.normal(scale=sigma[0] * np.sqrt(2))\n",
    "if N % 2 == 0:\n",
    "    mock_strain_f[-1] = np.random.normal(scale=sigma[-1] * np.sqrt(2))\n",
    "\n",
    "mock_strain = np.fft.irfft(mock_strain_f, n=N)\n",
    "\n",
    "# plot the strain and mock strain, to see they have similar amplitude\n",
    "plt.semilogy(freqs, np.abs(strain_f), alpha=0.5, label=\"strain\")\n",
    "plt.semilogy(freqs, np.abs(mock_strain_f), alpha=0.5, label=\"mock_strain\")\n",
    "plt.ylabel(r\"$|{\\rm strain}(f)|$\")\n",
    "plt.xlabel(\"frequency [Hz]\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "tags": []
   },
   "source": [
    "**calculate the SNR^2 for the mock data**\n",
    "**Plot the histograms of the mock SNR^2, real SNR^2, and the pdf of chi2 with two d.o.fs**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "wht_mock_strain_f = ()\n",
    "mock_z_cos = ()\n",
    "mock_z_sin = ()\n",
    "mock_snr2 = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_kwargs = {\n",
    "    \"histtype\": \"step\",\n",
    "    \"density\": True,\n",
    "    \"log\": True,\n",
    "    \"bins\": range(200),\n",
    "}\n",
    "\n",
    "counts, edges, patches = plt.hist(\n",
    "    snr2, **hist_kwargs, label=r\"real data SNR$^2$\"\n",
    ")\n",
    "counts, edges, patches = plt.hist(\n",
    "    mock_snr2, **hist_kwargs, label=r\"mock data SNR$^2$\"\n",
    ")\n",
    "plt.plot(edges, stats.chi2(df=2).pdf(edges), label=r\"$\\chi^2(2)$ pdf\")\n",
    "# focus on interesting portion of the histogram\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(1 / np.diff(edges).mean() / len(snr2) / 10)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6\n",
    "Glitches are short periods of time with strong power, not coming from the stationary noise nor an astrophysical GW transient. Since their shape is not related to the shape of GW transient, they will fail a signal-consistency test. This test is defined per-template. We will create a $h_{\\rm low}$ and $h_{\\rm high}$ :\n",
    "\\begin{align}\n",
    "    h_{\\rm low}(f) = \n",
    "    \\begin{cases}\n",
    "    h_{+}(f) & f< \\bar{f}\\\\\n",
    "    0 & f> \\bar{f}\n",
    "    \\end{cases}\n",
    "    \\\\\n",
    "    h_{\\rm high}(f) = \\begin{cases}\n",
    "        0 & f<\\bar{f}\\\\\n",
    "        h_{+}(f) & f>\\bar{f}\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "where $\\bar{f}$ is defined as the mid-point of the template accumulated SNR$^2$:\n",
    "\\begin{equation}\n",
    "    \\sum_{f=0}^{\\bar{f}} \\frac{|h_+|^2}{S_n(f)} {\\rm d}f= \\sum_{f=\\bar{f}}^{f_{\\rm max}}\\frac{|h_+|^2}{S_n(f)}{\\rm d}f\n",
    "\\end{equation}\n",
    "$h_{\\rm low}$ and $h_{\\rm high}$ are normalized to have unity norm ( $\\langle h_{\\rm low} | h_{\\rm low}\\rangle=\\langle h_{\\rm high}|h_{\\rm high}\\rangle=1$). This means that their complex-overlaps $z_{\\rm low}(t)$, $z_{\\rm high}(t)$ should be complex-normal random variables with variance of 1. The glitch-test $g(t)$ is defined as:\n",
    "\\begin{equation}\n",
    "    g(t) = \\frac{1}{2}|z_{\\rm low} - z_{\\rm high}|^2(t)\n",
    "\\end{equation}\n",
    "Under the noise hypothesis or under signal consistent with $h_+$, $g$ follows a $\\chi^2(2)$ distribution. In the presence of a glitch, $z_{\\rm low}$ and $z_{\\rm high}$ will have large amplitudes and different phases, which will lead to a large $g(t)$.\n",
    "\n",
    "To mark an element of the timeseries as a glitch, it has to both have ${\\rm SNR}\n",
    "^2$ larger than some value, which you will set by observing the ${\\rm SNR}^2$ histogram, AND that $g(t)$ has false-positive (probability to reject a measurement under the no-glitch hypothesis) of 1\\%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Create a test-statistic to detect glitches. \n",
    "\n",
    "Use it to remove glitches from the ${\\rm SNR}^2$ timeseries.\n",
    "\n",
    "**Plot the cleaned ${\\rm SNR}^{2}$ timeseries histogram. Overlay the theoretical prediction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find f_bar = where the cumulative SNR2 is equal half the overall SNR2\n",
    "frac_snr2 = np.cumsum(np.abs(wht_template) ** 2)\n",
    "frac_snr2 /= frac_snr2[-1]\n",
    "j = np.searchsorted(frac_snr2, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the the low and high frequencies templates\n",
    "wht_h_low, wht_h_high = np.zeros((2, len(freqs)), dtype=complex)\n",
    "# normalize them so each has norm 1\n",
    "wht_h_low[:j] = wht_template[:j] * 1 # this is wrong\n",
    "wht_h_high[j:] = wht_template[j:] * 1 # this is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check normalization of split templates\n",
    "print(\n",
    "    \"<h|h> = \",\n",
    "    np.fft.irfft(wht_template * wht_template.conj())[0]\n",
    "    ** (1 / 2),\n",
    ")\n",
    "print(\n",
    "    \"<h_low | h_low> = \",\n",
    "    np.fft.irfft(\n",
    "        wht_h_low * wht_h_low.conj()\n",
    "    )[0]\n",
    "    ** (1 / 2),\n",
    ")\n",
    "print(\n",
    "    \"<h_high | h_high> = \",\n",
    "    np.fft.irfft(\n",
    "        wht_h_high * wht_h_high.conj()\n",
    "    )[0]\n",
    "    ** (1 / 2),\n",
    ")\n",
    "print(\n",
    "    \"<h_low| h_high> = \",\n",
    "    np.fft.irfft(\n",
    "        wht_h_high * wht_h_low.conj()\n",
    "    )[0]\n",
    "    ** (1 / 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z_low = ()\n",
    "z_high = ()\n",
    "glitch_test_statistic = 0.5 * np.abs(z_low - z_high) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create 2 scatter plots of z_cos-z_sin (real vs imaginary) around and not around a glitch.\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n",
    "tslice = slice(*np.searchsorted(times, (100, 101)))\n",
    "axs[0].scatter(\n",
    "    (z_low - z_high)[tslice].real,\n",
    "    (z_low - z_high)[tslice].imag,\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axs[0].set_title(\"not around glitch\")\n",
    "tslice = slice(*np.searchsorted(times, (1258, 1259)))\n",
    "axs[1].scatter(\n",
    "    (z_low - z_high)[tslice].real,\n",
    "    (z_low - z_high)[tslice].imag,\n",
    "    s=1,\n",
    "    alpha=0.5,\n",
    ")\n",
    "axs[1].set_title(\"around glitch\")\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$z_\\cos - z_\\sin$ (real)\")\n",
    "    ax.set_ylabel(r\"$z_\\cos - z_\\sin$ (imaginary)\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "**Find a threshold on the chi2 glitch test statistic, such it will remove 1 in a 100 good signals.**\n",
    "\n",
    "**Create a glitch removal mask, if the glitch test is too high AND the SNR is above 5 (SNR^2 > 25).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glitch_test_threshold = 1  # this is wrong\n",
    "glitch_mask = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "hist_kwargs = {\n",
    "    \"histtype\": \"step\",\n",
    "    \"density\": True,\n",
    "    \"log\": True,\n",
    "    \"bins\": range(200),\n",
    "}\n",
    "counts, edges, patches = ax.hist(\n",
    "    snr2, **hist_kwargs, label=r\"SNR$^2$ before glitch-vetoing\"\n",
    ")\n",
    "counts, edges, patches = ax.hist(\n",
    "    snr2[~glitch_mask], **hist_kwargs, label=r\"SNR$^2$ after glitch vetoing\"\n",
    ")\n",
    "\n",
    "\n",
    "ax.plot(edges, stats.chi2(df=2).pdf(edges), label=r\"$\\chi^2(2)$\")\n",
    "y_lower_limit = 0.5 / (np.diff(edges).mean() * len(snr2))\n",
    "ax.set_xlim(right=100)\n",
    "ax.set_ylim(y_lower_limit)\n",
    "leg = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw_detection_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
